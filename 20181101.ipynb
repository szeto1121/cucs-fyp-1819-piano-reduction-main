{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things done these two weeks (2018-11-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-implemented the processing of scores and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'piano_reduction.compute_features' from '/Users/jason2yik/fyp/piano-reduction-main/piano_reduction/compute_features.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from piano_reduction import tools as pr, features as ft, compute_features as cf\n",
    "from piano_reduction.score_data import ScoreData\n",
    "import imp\n",
    "imp.reload(pr)\n",
    "imp.reload(ft)\n",
    "imp.reload(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measure</th>\n",
       "      <th>offset</th>\n",
       "      <th>part</th>\n",
       "      <th>ps</th>\n",
       "      <th>tie</th>\n",
       "      <th>x_train</th>\n",
       "      <th>color</th>\n",
       "      <th>y_train</th>\n",
       "      <th>duration</th>\n",
       "      <th>pitch</th>\n",
       "      <th>...</th>\n",
       "      <th>in_chord</th>\n",
       "      <th>lowest</th>\n",
       "      <th>occurrence</th>\n",
       "      <th>offset_value</th>\n",
       "      <th>onset_after_rest</th>\n",
       "      <th>pitch_distance</th>\n",
       "      <th>rhythm_variety</th>\n",
       "      <th>strong_beats</th>\n",
       "      <th>sustained_rhythm</th>\n",
       "      <th>vertical_doubling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;music21.duration.Duration 0.75&gt;</td>\n",
       "      <td>G2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>55.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;music21.duration.Duration 0.75&gt;</td>\n",
       "      <td>G3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;music21.duration.Duration 0.75&gt;</td>\n",
       "      <td>B3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>62.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;music21.duration.Duration 0.75&gt;</td>\n",
       "      <td>D4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;music21.duration.Duration 0.25&gt;</td>\n",
       "      <td>G2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      measure offset  part    ps   tie  x_train color  y_train  \\\n",
       "3843      0.0      0    -1  43.0  None        0   NaN        1   \n",
       "0         0.0      0    11  55.0  None        1  None        0   \n",
       "3844      0.0      0    -1  59.0  None        0   NaN        1   \n",
       "1         0.0      0     9  62.0  None        1  None        1   \n",
       "3845      0.0   0.75    -1  43.0  None        0   NaN        1   \n",
       "\n",
       "                              duration pitch        ...          in_chord  \\\n",
       "3843  <music21.duration.Duration 0.75>    G2        ...                 0   \n",
       "0     <music21.duration.Duration 0.75>    G3        ...                 0   \n",
       "3844  <music21.duration.Duration 0.75>    B3        ...                 0   \n",
       "1     <music21.duration.Duration 0.75>    D4        ...                 0   \n",
       "3845  <music21.duration.Duration 0.25>    G2        ...                 0   \n",
       "\n",
       "      lowest  occurrence  offset_value  onset_after_rest  pitch_distance  \\\n",
       "3843       0           0           0.0                 0             0.0   \n",
       "0          1           1           0.0                 0             5.0   \n",
       "3844       0           0           0.0                 0             0.0   \n",
       "1          0           1           0.0                 0             2.0   \n",
       "3845       0           0           0.0                 0             0.0   \n",
       "\n",
       "      rhythm_variety  strong_beats  sustained_rhythm  vertical_doubling  \n",
       "3843               0             0                 0                  0  \n",
       "0                  1             1                 1                  1  \n",
       "3844               0             0                 0                  0  \n",
       "1                  1             1                 1                  1  \n",
       "3845               0             0                 0                  0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ScoreData(pr.load_cosi(2))\n",
    "data.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save('score_data/cosi_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.load('score_data/cosi_2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data of the same score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2634, 25), (1733, 25))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data, testing_data = data.split(0.5)\n",
    "training_data.df.shape, testing_data.df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the models using the last-half of the score as training data and the first-half as testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras import backend as K\n",
    "from keras.callbacks import BaseLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', mode='max', min_delta=0, patience=100, verbose=0, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 200)               3200      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 201       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,401\n",
      "Trainable params: 3,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn = Sequential()\n",
    "nn.add(Dense(200, input_shape=[cf.feature_count()]))\n",
    "nn.add(Activation('sigmoid'))\n",
    "nn.add(Dense(1))\n",
    "nn.add(Activation('sigmoid'))\n",
    "nn.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f1])\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 200)               172800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 201       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 173,001\n",
      "Trainable params: 173,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(LSTM(200, input_shape=(None, cf.feature_count())))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(Dense(1))\n",
    "lstm.add(Activation('sigmoid'))\n",
    "lstm.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f1])\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12cb4ba90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ScoreData.load('score_data/cosi_2.pkl')\n",
    "testing_data, training_data = data.split()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "x_train, y_train = training_data.generate_data(length=-1)\n",
    "x_test, y_test = testing_data.generate_data(length=-1)\n",
    "lr = LogisticRegression().fit(x_train, y_train)\n",
    "nb = MultinomialNB().fit(x_train, y_train)\n",
    "nn.fit(x_train, y_train, epochs=1500, batch_size=32, validation_data=(x_test, y_test), callbacks=[early_stop], verbose=0)\n",
    "\n",
    "x_train, y_train = training_data.generate_data(length=10)\n",
    "x_test, y_test = testing_data.generate_data(length=10)\n",
    "lstm.fit(x_train, y_train, epochs=1500, batch_size=32, validation_data=(x_test, y_test), callbacks=[early_stop], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.save('models/NN.h5')\n",
    "lstm.save('models/LSTM.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With some baseline algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeepAll():\n",
    "    @classmethod\n",
    "    def predict(cls, x):\n",
    "        return [1 for _ in range(x.shape[0])]\n",
    "class KeepSome():\n",
    "    @classmethod\n",
    "    def predict(cls, x):\n",
    "        from random import randint\n",
    "        return [randint(0, 1) for _ in range(x.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results using the same piece (Cosi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from piano_reduction.score_data import ScoreData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Accuracy    F1 Score\n",
      "                      Keep All 0.490129081 0.657834395\n",
      "                     Keep Some 0.415337889 0.440000000\n",
      "           Logistic Regression 0.524677297 0.650864473\n",
      "                   Naive Bayes 0.441154138 0.561121049\n",
      "                 Dense Network 0.540622627 0.659730034\n",
      "          LSTM with 1 timestep 0.482156416 0.647909138\n",
      "        LSTM with 10 timesteps 0.509870919 0.547176429\n"
     ]
    }
   ],
   "source": [
    "data = ScoreData.load('score_data/cosi_2.pkl')\n",
    "validation_data, _ = data.split(0.5)\n",
    "from sklearn import metrics\n",
    "print('%30s %11s %11s' % ('', 'Accuracy', 'F1 Score'))\n",
    "models = [('Keep All', KeepAll, -1),\n",
    "          ('Keep Some', KeepSome, -1),\n",
    "          ('Logistic Regression', lr, -1), \n",
    "          ('Naive Bayes', nb, -1), \n",
    "          ('Dense Network', nn, -1), \n",
    "          ('LSTM with 1 timestep', lstm, 1), \n",
    "          ('LSTM with 10 timesteps', lstm, 10)]\n",
    "for name, model, length in models:\n",
    "    validation_data.get_y_pred(model, length, threshold=0.5)\n",
    "    print('%30s %.9f %.9f' % (name, \n",
    "                              metrics.accuracy_score(validation_data.df['y_train'], validation_data.df['y_pred']), \n",
    "                              metrics.f1_score(validation_data.df['y_train'], validation_data.df['y_pred'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data, _ = data.split(0.5)\n",
    "for name, model, length in models:\n",
    "    validation_data.get_y_pred(model, length)\n",
    "    validation_data.df[name] = validation_data.df['y_pred']\n",
    "validation_data.show_score(col=['x_train'] + [i[0] for i in models] + ['y_train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results using another piece (Symphony No.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Accuracy    F1 Score\n",
      "                      Keep All 0.501288660 0.667811159\n",
      "                     Keep Some 0.458762887 0.486552567\n",
      "           Logistic Regression 0.528350515 0.652751423\n",
      "                   Naive Bayes 0.506443299 0.661959400\n",
      "                 Dense Network 0.523195876 0.613778706\n",
      "          LSTM with 1 timestep 0.458762887 0.618181818\n",
      "        LSTM with 10 timesteps 0.492268041 0.360389610\n"
     ]
    }
   ],
   "source": [
    "data = ScoreData.load('score_data/2.pkl')\n",
    "validation_data, _ = data.split(0.5)\n",
    "from sklearn import metrics\n",
    "print('%30s %11s %11s' % ('', 'Accuracy', 'F1 Score'))\n",
    "models = [('Keep All', KeepAll, -1),\n",
    "          ('Keep Some', KeepSome, -1),\n",
    "          ('Logistic Regression', lr, -1), \n",
    "          ('Naive Bayes', nb, -1), \n",
    "          ('Dense Network', nn, -1), \n",
    "          ('LSTM with 1 timestep', lstm, 1), \n",
    "          ('LSTM with 10 timesteps', lstm, 10)]\n",
    "for name, model, length in models:\n",
    "    validation_data.get_y_pred(model, length)\n",
    "    print('%30s %.9f %.9f' % (name, \n",
    "                              metrics.accuracy_score(validation_data.df['y_train'], validation_data.df['y_pred']), \n",
    "                              metrics.f1_score(validation_data.df['y_train'], validation_data.df['y_pred'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data, _ = data.split(0.5)\n",
    "for name, model, length in models:\n",
    "    validation_data.get_y_pred(model, length)\n",
    "    validation_data.df[name] = validation_data.df['y_pred']\n",
    "validation_data.show_score(col=['x_train'] + [i[0] for i in models] + ['y_train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of lstm with binary vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 131,584\n",
      "Trainable params: 131,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm2 = Sequential()\n",
    "lstm2.add(LSTM(128, input_shape=(None, 128)))\n",
    "lstm2.add(Dropout(0.2))\n",
    "lstm2.add(Activation('sigmoid'))\n",
    "lstm2.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f1])\n",
    "lstm2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The result is not satisfying\n",
    "\n",
    "#### Too inaccurate\n",
    "\n",
    "#### Too slow\n",
    "\n",
    "#### May need even more time if all features are used as inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 50/2000 ...  - loss: 0.3465 - acc: 0.9900 - f1: 0.7264 - val_loss: 0.3314 - val_acc: 0.9831 - val_f1: 0.3801\n",
      "step: 100/2000 ...  - loss: 0.3464 - acc: 0.9902 - f1: 0.7331 - val_loss: 0.3317 - val_acc: 0.9830 - val_f1: 0.3705\n",
      "step: 150/2000 ...  - loss: 0.3463 - acc: 0.9902 - f1: 0.7348 - val_loss: 0.3318 - val_acc: 0.9827 - val_f1: 0.3617\n",
      "step: 200/2000 ...  - loss: 0.3460 - acc: 0.9904 - f1: 0.7403 - val_loss: 0.3319 - val_acc: 0.9828 - val_f1: 0.3596\n",
      "step: 250/2000 ...  - loss: 0.3460 - acc: 0.9903 - f1: 0.7382 - val_loss: 0.3317 - val_acc: 0.9829 - val_f1: 0.3600\n",
      "step: 300/2000 ...  - loss: 0.3460 - acc: 0.9903 - f1: 0.7372 - val_loss: 0.3319 - val_acc: 0.9828 - val_f1: 0.3569\n",
      "step: 350/2000 ...  - loss: 0.3459 - acc: 0.9904 - f1: 0.7402 - val_loss: 0.3318 - val_acc: 0.9829 - val_f1: 0.3602\n",
      "step: 400/2000 ...  - loss: 0.3460 - acc: 0.9904 - f1: 0.7403 - val_loss: 0.3317 - val_acc: 0.9828 - val_f1: 0.3580\n",
      "step: 450/2000 ...  - loss: 0.3461 - acc: 0.9904 - f1: 0.7405 - val_loss: 0.3322 - val_acc: 0.9828 - val_f1: 0.3576\n",
      "step: 500/2000 ...  - loss: 0.3462 - acc: 0.9904 - f1: 0.7410 - val_loss: 0.3326 - val_acc: 0.9826 - val_f1: 0.3527\n",
      "step: 550/2000 ...  - loss: 0.3459 - acc: 0.9903 - f1: 0.7383 - val_loss: 0.3328 - val_acc: 0.9825 - val_f1: 0.3496\n",
      "step: 600/2000 ...  - loss: 0.3461 - acc: 0.9904 - f1: 0.7388 - val_loss: 0.3329 - val_acc: 0.9825 - val_f1: 0.3474\n",
      "step: 650/2000 ...  - loss: 0.3459 - acc: 0.9903 - f1: 0.7372 - val_loss: 0.3328 - val_acc: 0.9826 - val_f1: 0.3497\n",
      "step: 700/2000 ...  - loss: 0.3463 - acc: 0.9904 - f1: 0.7413 - val_loss: 0.3329 - val_acc: 0.9825 - val_f1: 0.3500\n",
      "step: 750/2000 ...  - loss: 0.3459 - acc: 0.9904 - f1: 0.7404 - val_loss: 0.3342 - val_acc: 0.9825 - val_f1: 0.3480\n",
      "step: 800/2000 ...  - loss: 0.3459 - acc: 0.9904 - f1: 0.7406 - val_loss: 0.3335 - val_acc: 0.9826 - val_f1: 0.3488\n",
      "step: 850/2000 ...  - loss: 0.3459 - acc: 0.9904 - f1: 0.7402 - val_loss: 0.3338 - val_acc: 0.9825 - val_f1: 0.3475\n",
      "step: 900/2000 ...  - loss: 0.3459 - acc: 0.9905 - f1: 0.7424 - val_loss: 0.3337 - val_acc: 0.9825 - val_f1: 0.3449\n",
      "step: 950/2000 ...  - loss: 0.3459 - acc: 0.9904 - f1: 0.7407 - val_loss: 0.3328 - val_acc: 0.9826 - val_f1: 0.3473\n",
      "step: 1000/2000 ...  - loss: 0.3462 - acc: 0.9905 - f1: 0.7429 - val_loss: 0.3333 - val_acc: 0.9825 - val_f1: 0.3479\n",
      "step: 1050/2000 ...  - loss: 0.3459 - acc: 0.9904 - f1: 0.7409 - val_loss: 0.3330 - val_acc: 0.9825 - val_f1: 0.3493\n",
      "step: 1100/2000 ...  - loss: 0.3460 - acc: 0.9904 - f1: 0.7394 - val_loss: 0.3329 - val_acc: 0.9825 - val_f1: 0.3486\n",
      "step: 1150/2000 ...  - loss: 0.3462 - acc: 0.9904 - f1: 0.7409 - val_loss: 0.3329 - val_acc: 0.9825 - val_f1: 0.3479\n",
      "step: 1200/2000 ...  - loss: 0.3461 - acc: 0.9903 - f1: 0.7377 - val_loss: 0.3334 - val_acc: 0.9825 - val_f1: 0.3454\n",
      "step: 1250/2000 ...  - loss: 0.3460 - acc: 0.9904 - f1: 0.7393 - val_loss: 0.3333 - val_acc: 0.9824 - val_f1: 0.3454\n",
      "step: 1300/2000 ...  - loss: 0.3456 - acc: 0.9904 - f1: 0.7403 - val_loss: 0.3331 - val_acc: 0.9825 - val_f1: 0.3474\n",
      "step: 1350/2000 ...  - loss: 0.3458 - acc: 0.9904 - f1: 0.7395 - val_loss: 0.3328 - val_acc: 0.9825 - val_f1: 0.3432\n",
      "step: 1400/2000 ...  - loss: 0.3458 - acc: 0.9903 - f1: 0.7385 - val_loss: 0.3331 - val_acc: 0.9824 - val_f1: 0.3403\n",
      "step: 1450/2000 ...  - loss: 0.3458 - acc: 0.9904 - f1: 0.7416 - val_loss: 0.3336 - val_acc: 0.9825 - val_f1: 0.3451\n",
      "step: 1500/2000 ...  - loss: 0.3459 - acc: 0.9904 - f1: 0.7385 - val_loss: 0.3335 - val_acc: 0.9825 - val_f1: 0.3438\n",
      "step: 1550/2000 ...  - loss: 0.3462 - acc: 0.9903 - f1: 0.7371 - val_loss: 0.3334 - val_acc: 0.9824 - val_f1: 0.3459\n",
      "step: 1600/2000 ...  - loss: 0.3459 - acc: 0.9903 - f1: 0.7385 - val_loss: 0.3332 - val_acc: 0.9826 - val_f1: 0.3472\n",
      "step: 1650/2000 ...  - loss: 0.3460 - acc: 0.9904 - f1: 0.7416 - val_loss: 0.3331 - val_acc: 0.9826 - val_f1: 0.3459\n",
      "step: 1700/2000 ...  - loss: 0.3461 - acc: 0.9904 - f1: 0.7408 - val_loss: 0.3332 - val_acc: 0.9826 - val_f1: 0.3481\n",
      "step: 1750/2000 ...  - loss: 0.3459 - acc: 0.9904 - f1: 0.7382 - val_loss: 0.3331 - val_acc: 0.9826 - val_f1: 0.3495\n",
      "step: 1800/2000 ...  - loss: 0.3460 - acc: 0.9904 - f1: 0.7392 - val_loss: 0.3329 - val_acc: 0.9827 - val_f1: 0.3526\n",
      "step: 1850/2000 ...  - loss: 0.3463 - acc: 0.9904 - f1: 0.7407 - val_loss: 0.3329 - val_acc: 0.9827 - val_f1: 0.3574\n",
      "step: 1900/2000 ...  - loss: 0.3460 - acc: 0.9904 - f1: 0.7394 - val_loss: 0.3329 - val_acc: 0.9826 - val_f1: 0.3510\n",
      "step: 1950/2000 ...  - loss: 0.3459 - acc: 0.9904 - f1: 0.7398 - val_loss: 0.3333 - val_acc: 0.9825 - val_f1: 0.3522\n",
      "step: 2000/2000 ...  - loss: 0.3460 - acc: 0.9904 - f1: 0.7403 - val_loss: 0.3331 - val_acc: 0.9825 - val_f1: 0.3497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13c3fd358>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sd.ScoreData.load('score_data/2.pkl')\n",
    "testing_data, training_data = data.split()\n",
    "x_train, y_train = training_data.generate_data_2(length=16)\n",
    "x_test, y_test = testing_data.generate_data_2(length=16)\n",
    "logger = NBatchLogger(display=50)\n",
    "early_stop = EarlyStopping(monitor='f1', mode='max', min_delta=0, patience=2000, verbose=0, restore_best_weights=False)\n",
    "lstm2.fit(x_train, y_train, epochs=2000, batch_size=32, validation_data=(x_test, y_test), callbacks=[early_stop, logger], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Size of inputs affect the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Accuracy    F1 score\n",
      "            LSTM with binary 1 0.497542998 0.443537415\n",
      "            LSTM with binary 2 0.472123369 0.340740741\n",
      "            LSTM with binary 3 0.465577596 0.273015873\n",
      "            LSTM with binary 4 0.457044674 0.252365931\n",
      "            LSTM with binary 5 0.461797753 0.261941448\n",
      "            LSTM with binary 6 0.473509934 0.251177394\n",
      "            LSTM with binary 7 0.477546550 0.239234450\n",
      "            LSTM with binary 8 0.484187568 0.255118110\n",
      "            LSTM with binary 9 0.480998914 0.255451713\n",
      "           LSTM with binary 10 0.485342020 0.273006135\n",
      "           LSTM with binary 11 0.483170467 0.285285285\n",
      "           LSTM with binary 12 0.491323210 0.303120357\n",
      "           LSTM with binary 13 0.494577007 0.310650888\n",
      "           LSTM with binary 14 0.491874323 0.305185185\n",
      "           LSTM with binary 15 0.489707476 0.306332842\n",
      "           LSTM with binary 16 0.486486486 0.304538799\n",
      "           LSTM with binary 17 0.485405405 0.302052786\n",
      "           LSTM with binary 18 0.486486486 0.304538799\n",
      "           LSTM with binary 19 0.486486486 0.300441826\n",
      "           LSTM with binary 20 0.489729730 0.299703264\n",
      "           LSTM with binary 21 0.489729730 0.301775148\n",
      "           LSTM with binary 22 0.489729730 0.301775148\n",
      "           LSTM with binary 23 0.490810811 0.304283604\n",
      "           LSTM with binary 24 0.491891892 0.304733728\n",
      "           LSTM with binary 25 0.487567568 0.300884956\n",
      "           LSTM with binary 26 0.488648649 0.303387334\n",
      "           LSTM with binary 27 0.490280778 0.305882353\n",
      "           LSTM with binary 28 0.491360691 0.306332842\n",
      "           LSTM with binary 29 0.492440605 0.306784661\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = ScoreData.load('score_data/2.pkl')\n",
    "validation_data, _ = data.split(0.5)\n",
    "from sklearn import metrics\n",
    "print('%30s %11s %11s' % ('', 'Accuracy', 'F1 score'))\n",
    "for l in range(1, 30):\n",
    "    models = [('LSTM with binary %d' % l, lstm2, l)]\n",
    "    for name, model, length in models:\n",
    "        validation_data = validation_data.merge_binary((lstm2.predict(validation_data.generate_data_2(length=length)[0]) > 0.5) * 1, skip_features=True)\n",
    "        print('%30s %.9f %.9f' % (name, \n",
    "                                  metrics.accuracy_score(validation_data.df['y_train'], validation_data.df['y_pred']), \n",
    "                                  metrics.f1_score(validation_data.df['y_train'], validation_data.df['y_pred'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data.show_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start implementing the postprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm2.save('models/LSTM_binary.h5')\n",
    "from keras.models import load_model\n",
    "lstm3 = load_model('models/LSTM_binary.h5', custom_objects={'f1': f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "class NBatchLogger(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    A Logger that log average performance per `display` steps.\n",
    "    \"\"\"\n",
    "    def __init__(self, display):\n",
    "        self.step = 0\n",
    "        self.display = display\n",
    "        self.metric_cache = {}\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.step += 1\n",
    "        for k in self.params['metrics']:\n",
    "            if k in logs:\n",
    "                self.metric_cache[k] = self.metric_cache.get(k, 0) + logs[k]\n",
    "        if self.step % self.display == 0:\n",
    "            metrics_log = ''\n",
    "            for (k, v) in self.metric_cache.items():\n",
    "                val = v / self.display\n",
    "                if abs(val) > 1e-3:\n",
    "                    metrics_log += ' - %s: %.4f' % (k, val)\n",
    "                else:\n",
    "                    metrics_log += ' - %s: %.4e' % (k, val)\n",
    "            print('step: {}/{} ... {}'.format(self.step,\n",
    "                                          self.params['epochs'],\n",
    "                                          metrics_log))\n",
    "            self.metric_cache.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
