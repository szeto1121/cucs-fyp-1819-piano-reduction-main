{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things done these two weeks (2018-11-15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated training data using our own models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'piano_reduction.compute_features' from '/Users/jason2yik/fyp/piano-reduction-main/piano_reduction/compute_features.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from piano_reduction import tools as pr, features as ft, compute_features as cf\n",
    "from piano_reduction.score_data import ScoreData\n",
    "import imp\n",
    "imp.reload(pr)\n",
    "imp.reload(ft)\n",
    "imp.reload(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ScoreData.load('score_data/cosi_2.pkl')\n",
    "testing_data, training_data = data.split()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "x_train, y_train = training_data.generate_data(length=-1)\n",
    "x_test, y_test = testing_data.generate_data(length=-1)\n",
    "lr_0 = LogisticRegression().fit(x_train, y_train)\n",
    "nb_0 = MultinomialNB().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ScoreData.load('score_data/5.pkl')\n",
    "data = data.get_y_pred(lr_0, length=-1)\n",
    "data.df['y_train'] = data.df['y_pred']\n",
    "data.df = data.df.query(\"(y_train == 1) or (x_train == 1)\")\n",
    "del data.df['y_pred']\n",
    "data.save('own_output/lr/5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ScoreData.load('own_output/lr/3.pkl')\n",
    "data.show_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implemented new metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(y_train, y_pred):\n",
    "    s = set()\n",
    "    t = set()\n",
    "    for i in range(0, len(y_train)):\n",
    "        for j in range(0, 128):\n",
    "            if y_train[i, j] == 1:\n",
    "                t.add((i, j))\n",
    "    for i in range(0, len(y_pred)):\n",
    "        for j in range(0, 128):\n",
    "            if y_pred[i, j] == 1:\n",
    "                s.add((i, j))\n",
    "    return len(s&t) * 1.0 / (len(s) + len(t) - len(s&t))\n",
    "\n",
    "def pitch_class_jaccard_similarity(y_train, y_pred):\n",
    "    s = set()\n",
    "    t = set()\n",
    "    for i in range(0, len(y_train)):\n",
    "        for j in range(0, 128):\n",
    "            if y_train[i, j] == 1:\n",
    "                t.add((i, j % 12))\n",
    "    for i in range(0, len(y_pred)):\n",
    "        for j in range(0, 128):\n",
    "            if y_pred[i, j] == 1:\n",
    "                s.add((i, j % 12))\n",
    "    return len(s&t) * 1.0 / (len(s) + len(t) - len(s&t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ScoreData.load('own_output/lr/3.pkl')\n",
    "testing_data, training_data = data.split()\n",
    "x_train, y_train = training_data.generate_data(length=-1)\n",
    "x_test, y_test = testing_data.generate_data(length=-1)\n",
    "lr = LogisticRegression().fit(x_train, y_train)\n",
    "nb = MultinomialNB().fit(x_train, y_train)\n",
    "nn = pr.dense()\n",
    "nn.fit(x_train, y_train, epochs=1500, batch_size=32, validation_data=(x_test, y_test), callbacks=[pr.early_stop()], verbose=0)\n",
    "\n",
    "x_train, y_train = training_data.generate_data(length=1)\n",
    "x_test, y_test = testing_data.generate_data(length=1)\n",
    "lstm_1 = pr.lstm()\n",
    "lstm_1.fit(x_train, y_train, epochs=1500, batch_size=32, validation_data=(x_test, y_test), callbacks=[pr.early_stop()], verbose=0)\n",
    "\n",
    "x_train, y_train = training_data.generate_data(length=5)\n",
    "x_test, y_test = testing_data.generate_data(length=5)\n",
    "lstm_5 = pr.lstm()\n",
    "lstm_5.fit(x_train, y_train, epochs=1500, batch_size=32, validation_data=(x_test, y_test), callbacks=[pr.early_stop()], verbose=0)\n",
    "\n",
    "x_train, y_train = training_data.generate_data(length=10)\n",
    "x_test, y_test = testing_data.generate_data(length=10)\n",
    "lstm_10 = pr.lstm()\n",
    "lstm_10.fit(x_train, y_train, epochs=1500, batch_size=32, validation_data=(x_test, y_test), callbacks=[pr.early_stop()], verbose=0)\n",
    "\n",
    "class KeepAll():\n",
    "    @classmethod\n",
    "    def predict(cls, x):\n",
    "        return [1 for _ in range(x.shape[0])]\n",
    "class KeepSome():\n",
    "    @classmethod\n",
    "    def predict(cls, x):\n",
    "        from random import randint\n",
    "        return [randint(0, 1) for _ in range(x.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129283550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = training_data.generate_data(length=1)\n",
    "x_test, y_test = testing_data.generate_data(length=1)\n",
    "gru_1 = pr.gru()\n",
    "gru_1.fit(x_train, y_train, epochs=1500, batch_size=32, validation_data=(x_test, y_test), callbacks=[pr.early_stop()], verbose=0)\n",
    "\n",
    "x_train, y_train = training_data.generate_data(length=5)\n",
    "x_test, y_test = testing_data.generate_data(length=5)\n",
    "gru_5 = pr.gru()\n",
    "gru_5.fit(x_train, y_train, epochs=1500, batch_size=32, validation_data=(x_test, y_test), callbacks=[pr.early_stop()], verbose=0)\n",
    "\n",
    "x_train, y_train = training_data.generate_data(length=10)\n",
    "x_test, y_test = testing_data.generate_data(length=10)\n",
    "gru_10 = pr.gru()\n",
    "gru_10.fit(x_train, y_train, epochs=1500, batch_size=32, validation_data=(x_test, y_test), callbacks=[pr.early_stop()], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Jaccard Similarity        Ignore Octave             Accuracy             F1 score\n",
      "                      Keep All           0.81160365           0.92913386           0.81160365           0.89600576\n",
      "                     Keep Some           0.46137184           0.65997323           0.51368970           0.63142292\n",
      "           Logistic Regression           0.97187500           0.98194444           0.97653194           0.98573693\n",
      "                   Naive Bayes           0.84392265           0.92980132           0.85267275           0.91535581\n",
      "                            NN           0.98416469           0.99020979           0.98696219           0.99201915\n",
      "                   LSTM with 1           0.97100313           0.98467967           0.97588005           0.98528827\n",
      "                   LSTM with 5           0.97470356           0.98603352           0.97913950           0.98718975\n",
      "                  LSTM with 10           0.95746326           0.97520661           0.96414602           0.97826946\n",
      "                    GRU with 1           0.97180893           0.98470097           0.97653194           0.98570294\n",
      "                    GRU with 5           0.95003965           0.96787709           0.95893090           0.97437983\n",
      "                   GRU with 10           0.95517774           0.97386520           0.96219035           0.97707510\n"
     ]
    }
   ],
   "source": [
    "print('%30s %20s %20s %20s %20s' % ('', 'Jaccard Similarity', 'Ignore Octave', 'Accuracy', 'F1 score'))\n",
    "models = [('Keep All', KeepAll, -1),\n",
    "          ('Keep Some', KeepSome, -1),\n",
    "          ('Logistic Regression', lr, -1), \n",
    "          ('Naive Bayes', nb, -1),\n",
    "          ('NN', nn, -1),\n",
    "          ('LSTM with 1', lstm_1, 1),\n",
    "          ('LSTM with 5', lstm_5, 5),\n",
    "          ('LSTM with 10', lstm_10, 10),\n",
    "          ('GRU with 1', gru_1, 1),\n",
    "          ('GRU with 5', gru_5, 5),\n",
    "          ('GRU with 10', gru_10, 10),\n",
    "         ]\n",
    "from sklearn import metrics\n",
    "for name, model, length in models:\n",
    "    data = ScoreData.load('own_output/lr/2.pkl')\n",
    "    validation_data, _ = data.split(0.5)\n",
    "    validation_data = data\n",
    "    validation_data = validation_data.get_y_pred(model, length, threshold=0.5)\n",
    "    tmptrain = validation_data.to_binary('y_train')\n",
    "    tmppred = validation_data.to_binary('y_pred')\n",
    "    print('%30s %20.8f %20.8f %20.8f %20.8f' % (name,\n",
    "                                jaccard_similarity(tmptrain, tmppred),\n",
    "                                pitch_class_jaccard_similarity(tmptrain, tmppred),\n",
    "                                metrics.accuracy_score(validation_data.df['y_train'], validation_data.df['y_pred']), \n",
    "                                metrics.f1_score(validation_data.df['y_train'], validation_data.df['y_pred'])\n",
    "                               ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ScoreData.load('own_output/lr/3.pkl')\n",
    "data = data.get_y_pred(lstm_10, 10)\n",
    "data.save('intermediate/3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implemented a basic postprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ScoreData.load('intermediate/3.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = data.to_binary('y_pred')\n",
    "for i in range(0,len(data_pred)):\n",
    "    cnt = 0\n",
    "    highest = -1\n",
    "    lowest = 129\n",
    "    for j in range(0,128):\n",
    "        if data_pred[i][j] == 1:\n",
    "            highest = max(highest,j)\n",
    "            lowest = min(lowest,j)\n",
    "    for j in range(60,128):\n",
    "        if data_pred[i][j] ==1 and j < highest-12:\n",
    "            data_pred[i][j] = 0\n",
    "            data_pred[i][j+12] = 1\n",
    "    for j in reversed(range(0, 60)):\n",
    "        if data_pred[i][j] == 1 and j > lowest + 12:\n",
    "            data_pred[i][j] = 0\n",
    "            data_pred[i][j - 12] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = data.to_binary('y_pred')\n",
    "for i in range(0,len(data_pred)):\n",
    "    cnt = 0\n",
    "    highest = -1\n",
    "    lowest = -1\n",
    "    for j in range(0,128):\n",
    "        if data_pred[i][j] == 1:\n",
    "            highest = max(highest,j)\n",
    "            if j < 60:\n",
    "                lowest = max(lowest,j)\n",
    "    for j in range(60,128):\n",
    "        if data_pred[i][j] ==1 and j < highest-12:\n",
    "            data_pred[i][j] = 0\n",
    "            data_pred[i][j+12] = 1\n",
    "    for j in range(0, 60):\n",
    "        if data_pred[i][j] == 1 and j < lowest - 12:\n",
    "            data_pred[i][j] = 0\n",
    "            data_pred[i][j + 12] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.merge_binary(data_pred, name='post', skip_features=True)\n",
    "new_data.show_score(col=['x_train', 'y_train', 'y_pred', 'post'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continued experimenting binary vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 131,584\n",
      "Trainable params: 131,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_14 (GRU)                 (None, 128)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 98,688\n",
      "Trainable params: 98,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(128, input_shape=(None, 128)))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', pr.f1])\n",
    "model2.summary()\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(GRU(128, input_shape=(None, 128)))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', pr.f1])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length = 1, key = 2\n",
      "step: 200/200 ...  - loss: 0.4475 - acc: 0.9830 - f1: 0.3690 - val_loss: 0.4417 - val_acc: 0.9802 - val_f1: 0.2277\n",
      "step: 200/200 ...  - loss: 0.3910 - acc: 0.9834 - f1: 0.4203 - val_loss: 0.3777 - val_acc: 0.9800 - val_f1: 0.2487\n",
      "length = 2, key = -5\n",
      "step: 200/200 ...  - loss: 0.3609 - acc: 0.9864 - f1: 0.4828 - val_loss: 0.3397 - val_acc: 0.9834 - val_f1: 0.3366\n",
      "step: 200/200 ...  - loss: 0.3481 - acc: 0.9901 - f1: 0.6703 - val_loss: 0.3264 - val_acc: 0.9871 - val_f1: 0.5694\n",
      "length = 6, key = 0\n",
      "step: 200/200 ...  - loss: 0.3521 - acc: 0.9861 - f1: 0.4647 - val_loss: 0.3282 - val_acc: 0.9843 - val_f1: 0.3990\n",
      "step: 200/200 ...  - loss: 0.3450 - acc: 0.9924 - f1: 0.7695 - val_loss: 0.3226 - val_acc: 0.9906 - val_f1: 0.7351\n",
      "length = 4, key = 4\n",
      "step: 200/200 ...  - loss: 0.3521 - acc: 0.9858 - f1: 0.4459 - val_loss: 0.3274 - val_acc: 0.9849 - val_f1: 0.4289\n",
      "step: 200/200 ...  - loss: 0.3451 - acc: 0.9923 - f1: 0.7656 - val_loss: 0.3222 - val_acc: 0.9909 - val_f1: 0.7573\n",
      "length = 6, key = 8\n",
      "step: 200/200 ...  - loss: 0.3525 - acc: 0.9831 - f1: 0.2410 - val_loss: 0.3267 - val_acc: 0.9848 - val_f1: 0.4324\n",
      "step: 200/200 ...  - loss: 0.3470 - acc: 0.9907 - f1: 0.7029 - val_loss: 0.3222 - val_acc: 0.9909 - val_f1: 0.7543\n",
      "length = 5, key = -9\n",
      "step: 200/200 ...  - loss: 0.3511 - acc: 0.9843 - f1: 0.3485 - val_loss: 0.3261 - val_acc: 0.9850 - val_f1: 0.4393\n",
      "step: 200/200 ...  - loss: 0.3467 - acc: 0.9910 - f1: 0.7179 - val_loss: 0.3222 - val_acc: 0.9908 - val_f1: 0.7488\n",
      "length = 4, key = 9\n",
      "step: 200/200 ...  - loss: 0.3510 - acc: 0.9857 - f1: 0.4332 - val_loss: 0.3258 - val_acc: 0.9850 - val_f1: 0.4448\n",
      "step: 200/200 ...  - loss: 0.3450 - acc: 0.9923 - f1: 0.7703 - val_loss: 0.3215 - val_acc: 0.9916 - val_f1: 0.7877\n",
      "length = 6, key = 7\n",
      "step: 200/200 ...  - loss: 0.3488 - acc: 0.9877 - f1: 0.5560 - val_loss: 0.3252 - val_acc: 0.9855 - val_f1: 0.4836\n",
      "step: 200/200 ...  - loss: 0.3440 - acc: 0.9930 - f1: 0.7946 - val_loss: 0.3215 - val_acc: 0.9915 - val_f1: 0.7794\n",
      "length = 2, key = 9\n",
      "step: 200/200 ...  - loss: 0.3562 - acc: 0.9871 - f1: 0.5202 - val_loss: 0.3340 - val_acc: 0.9859 - val_f1: 0.4965\n",
      "step: 200/200 ...  - loss: 0.3438 - acc: 0.9932 - f1: 0.7958 - val_loss: 0.3216 - val_acc: 0.9914 - val_f1: 0.7775\n",
      "length = 5, key = -4\n",
      "step: 200/200 ...  - loss: 0.3499 - acc: 0.9842 - f1: 0.3409 - val_loss: 0.3246 - val_acc: 0.9857 - val_f1: 0.4861\n",
      "step: 200/200 ...  - loss: 0.3462 - acc: 0.9913 - f1: 0.7327 - val_loss: 0.3215 - val_acc: 0.9915 - val_f1: 0.7692\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "data = ScoreData.load('own_output/lr/3.pkl')\n",
    "\n",
    "for _ in range(10):\n",
    "    length = randint(1, 6)\n",
    "    if _ == 0:\n",
    "        length = 1\n",
    "    key = randint(-12, 12)\n",
    "    testing_data, training_data = data.split()\n",
    "    training_data.df['ps'] -= key\n",
    "    x_train, y_train = training_data.generate_data_2(length=length)\n",
    "    x_test, y_test = testing_data.generate_data_2(length=length)\n",
    "    print('length = %d, key = %d' % (length, key))\n",
    "    logger = pr.NBatchLogger(display=200)\n",
    "    model2.fit(x_train, y_train, epochs=200, batch_size=64, validation_data=(x_test, y_test), callbacks=[logger], verbose=0)\n",
    "    logger = pr.NBatchLogger(display=200)\n",
    "    model3.fit(x_train, y_train, epochs=200, batch_size=64, validation_data=(x_test, y_test), callbacks=[logger], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU train faster than LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Jaccard Similarity   Ignore Octave        Accuracy        F1 score   roc_auc_score\n",
      "                   LSTM with 1           0.31130614      0.48346264      0.41848300      0.47480315      0.81262274\n",
      "                   LSTM with 2           0.32707845      0.50595972      0.43722755      0.49293009      0.86882672\n",
      "                   LSTM with 3           0.31438302      0.48847737      0.43034393      0.47837353      0.87853254\n",
      "                   LSTM with 4           0.31621692      0.49052718      0.43236190      0.48049363      0.86222058\n",
      "                   LSTM with 5           0.31294490      0.48405797      0.43360139      0.47670683      0.86368147\n",
      "                   LSTM with 6           0.31157505      0.48277293      0.43344933      0.47511586      0.85686300\n",
      "                   LSTM with 7           0.30897538      0.47797174      0.43211488      0.47208738      0.84010818\n",
      "                   LSTM with 8           0.30693856      0.47609148      0.43046790      0.46970618      0.83808208\n",
      "\n",
      "                    GRU with 1           0.38162137      0.58326818      0.44889163      0.55242540      0.88111602\n",
      "                    GRU with 2           0.40644244      0.62490272      0.45379250      0.57797238      0.87793522\n",
      "                    GRU with 3           0.40757504      0.62300195      0.45793374      0.57911660      0.88059175\n",
      "                    GRU with 4           0.40928571      0.62485392      0.45924150      0.58084136      0.88056517\n",
      "                    GRU with 5           0.40952381      0.62485392      0.45945946      0.58108108      0.88020019\n",
      "                    GRU with 6           0.40952381      0.62485392      0.45945946      0.58108108      0.88071430\n",
      "                    GRU with 7           0.40952381      0.62485392      0.45945946      0.58108108      0.88031051\n",
      "                    GRU with 8           0.40952381      0.62485392      0.45945946      0.58108108      0.88005000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = ScoreData.load('score_data/4.pkl')\n",
    "from sklearn import metrics\n",
    "print('%30s %20s %15s %15s %15s %15s' % ('', 'Jaccard Similarity', 'Ignore Octave', 'Accuracy', 'F1 score', 'roc_auc_score'))\n",
    "for name, model in [('LSTM', model2), ('GRU', model3)]:\n",
    "    for length in range(1, 9):\n",
    "        validation_data = data\n",
    "        validation_data = validation_data.merge_binary((model.predict(validation_data.generate_data_2(length=length)[0]) > 0.5) * 1, skip_features=True)\n",
    "        tmptrain = validation_data.to_binary('y_train')\n",
    "        tmppred = validation_data.to_binary('y_pred')\n",
    "        print('%30s %20.8f %15.8f %15.8f %15.8f %15.8f' % ('%s with %d' % (name, length),\n",
    "                                    jaccard_similarity(tmptrain, tmppred),\n",
    "                                    pitch_class_jaccard_similarity(tmptrain, tmppred),\n",
    "                                    metrics.accuracy_score(validation_data.df['y_train'], validation_data.df['y_pred']), \n",
    "                                    metrics.f1_score(validation_data.df['y_train'], validation_data.df['y_pred']),\n",
    "                                    metrics.roc_auc_score(validation_data.to_binary('y_train').flatten(), model.predict(validation_data.generate_data_2(length=length)[0]).flatten())\n",
    "                                   ))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9413706502967256"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ScoreData.load('own_output/lr/2.pkl')\n",
    "validation_data = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('models/20181115/lstm.h5')\n",
    "model3.save('models/20181115/gru.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ScoreData.load('own_output/lr/2.pkl')\n",
    "data = data.merge_binary((model3.predict(validation_data.generate_data_2(length=6)[0]) > 0.5) * 1, skip_features=True)\n",
    "data.show_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
