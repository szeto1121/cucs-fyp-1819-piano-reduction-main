{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'piano_reduction.compute_features' from '/home/szeto/Documents/fyp/piano-reduction-main/piano_reduction/compute_features.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from piano_reduction import tools as pr, features as ft, compute_features as cf\n",
    "from piano_reduction.score_data import ScoreData\n",
    "import imp\n",
    "imp.reload(pr)\n",
    "imp.reload(ft)\n",
    "imp.reload(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ScoreData.load('score_data/cosi_2.pkl')\n",
    "testing_data, training_data = data.split()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "x_train, y_train = training_data.generate_data(length=-1)\n",
    "x_test, y_test = testing_data.generate_data(length=-1)\n",
    "lr = LogisticRegression().fit(x_train, y_train)\n",
    "nb = MultinomialNB().fit(x_train, y_train)\n",
    "#nn.fit(x_train, y_train, epochs=1500, batch_size=32, validation_data=(x_test, y_test), callbacks=[early_stop], verbose=0)\n",
    "\n",
    "#x_train, y_train = training_data.generate_data(length=10)\n",
    "#x_test, y_test = testing_data.generate_data(length=10)\n",
    "#lstm.fit(x_train, y_train, epochs=1500, batch_size=32, validation_data=(x_test, y_test), callbacks=[early_stop], verbose=0)\n",
    "class KeepAll():\n",
    "    @classmethod\n",
    "    def predict(cls, x):\n",
    "        return [1 for _ in range(x.shape[0])]\n",
    "class KeepSome():\n",
    "    @classmethod\n",
    "    def predict(cls, x):\n",
    "        from random import randint\n",
    "        return [randint(0, 1) for _ in range(x.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Jaccard Similarity Ignore Octave    Accuracy    F1 Score\n",
      "                      Keep All 0.501288660 0.729216152    0.501288660 0.667811159\n",
      "                     Keep Some 0.296357616 0.510256410    0.452319588 0.457215837\n",
      "           Logistic Regression 0.484507042 0.712895377    0.528350515 0.652751423\n",
      "                   Naive Bayes 0.494722955 0.723809524    0.506443299 0.661959400\n"
     ]
    }
   ],
   "source": [
    "data = ScoreData.load('score_data/2.pkl')\n",
    "validation_data, _ = data.split(0.5)\n",
    "from sklearn import metrics\n",
    "print('%30s %11s %11s %11s %11s' % ('', 'Jaccard Similarity', 'Ignore Octave', 'Accuracy' , 'F1 Score'))\n",
    "models = [('Keep All', KeepAll, -1),\n",
    "          ('Keep Some', KeepSome, -1),\n",
    "          ('Logistic Regression', lr, -1), \n",
    "          ('Naive Bayes', nb, -1)]\n",
    "for name, model, length in models:\n",
    "    validation_data.get_y_pred(model, length, threshold=0.5)\n",
    "    tmptrain = validation_data.to_binary('y_train')\n",
    "    tmppred = validation_data.to_binary('y_pred')\n",
    "    s1 = set()\n",
    "    t1 = set()\n",
    "    s2 = set()\n",
    "    t2 = set()\n",
    "    for i in range(0,len(tmptrain)):\n",
    "        for j in range(0,128):\n",
    "            if tmptrain[i][j]==1:\n",
    "                t1.add((i,j))\n",
    "                t2.add((i,j%12))\n",
    "    for i in range(0,len(tmppred)):\n",
    "        for j in range(0,128):\n",
    "            if tmppred[i][j]==1:\n",
    "                s1.add((i,j))\n",
    "                s2.add((i,j%12))\n",
    "    print('%30s %.9f %.9f    %.9f %.9f' % (name , len(s1&t1)*1.0/(len(s1) + len(t1)- len(s1&t1)) , len(s2&t2)*1.0/(len(s2) + len(t2)- len(s2&t2)),\n",
    "                              metrics.accuracy_score(validation_data.df['y_train'], validation_data.df['y_pred']), \n",
    "                              metrics.f1_score(validation_data.df['y_train'], validation_data.df['y_pred'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szeto/Documents/fyp/piano-reduction-main/piano_reduction/score_data.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.df['y_pred'] = tmp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Jaccard Similarity Ignore Octave    Accuracy    F1 Score\n",
      "                      Keep All 0.811603651 0.929133858    0.811603651 0.896005757\n",
      "                     Keep Some 0.453247680 0.669365722    0.500651890 0.623772102\n",
      "           Logistic Regression 0.971653543 0.983240223    0.976531943 0.985623003\n",
      "                   Naive Bayes 0.800738007 0.904183536    0.823989570 0.889344262\n",
      "                            NN 0.946750196 0.986033520    0.955671447 0.972646822\n"
     ]
    }
   ],
   "source": [
    "new_data = data.copy()\n",
    "new_data.get_y_pred(lr, length=-1)\n",
    "new_data.df['y_train'] = new_data.df['y_pred']\n",
    "new_data.df = new_data.df.query(\"(y_train == 1) or (x_train == 1)\")\n",
    "del new_data.df['y_pred']\n",
    "testing_data, training_data = new_data.split()\n",
    "x_train, y_train = training_data.generate_data(length=-1)\n",
    "x_test, y_test = testing_data.generate_data(length=-1)\n",
    "lr = LogisticRegression().fit(x_train, y_train)\n",
    "nb = MultinomialNB().fit(x_train, y_train)\n",
    "nn.fit(x_train, y_train, epochs=1500, batch_size=32, validation_data=(x_test, y_test), callbacks=[early_stop], verbose=0)\n",
    "validation_data, _ = new_data.split(0.5)\n",
    "validation_data = new_data\n",
    "validation_data.get_y_pred(lr, length=-1,threshold = 0.5)\n",
    "tmptrain = validation_data.to_binary('y_train')\n",
    "tmppred = validation_data.to_binary('y_pred')\n",
    "\n",
    "print('%30s %11s %11s %11s %11s' % ('', 'Jaccard Similarity', 'Ignore Octave', 'Accuracy' , 'F1 Score'))\n",
    "models = [('Keep All', KeepAll, -1),\n",
    "          ('Keep Some', KeepSome, -1),\n",
    "          ('Logistic Regression', lr, -1), \n",
    "          ('Naive Bayes', nb, -1),\n",
    "          ('NN', nn, -1)\n",
    "         ]\n",
    "for name, model, length in models:\n",
    "    validation_data.get_y_pred(model, length, threshold=0.5)\n",
    "    tmptrain = validation_data.to_binary('y_train')\n",
    "    tmppred = validation_data.to_binary('y_pred')\n",
    "    s1 = set()\n",
    "    t1 = set()\n",
    "    s2 = set()\n",
    "    t2 = set()\n",
    "    for i in range(0,len(tmptrain)):\n",
    "        for j in range(0,128):\n",
    "            if tmptrain[i][j]==1:\n",
    "                t1.add((i,j))\n",
    "                t2.add((i,j%12))\n",
    "    for i in range(0,len(tmppred)):\n",
    "        for j in range(0,128):\n",
    "            if tmppred[i][j]==1:\n",
    "                s1.add((i,j))\n",
    "                s2.add((i,j%12))\n",
    "    print('%30s %.9f %.9f    %.9f %.9f' % (name , len(s1&t1)*1.0/(len(s1) + len(t1)- len(s1&t1)) , len(s2&t2)*1.0/(len(s2) + len(t2)- len(s2&t2)),\n",
    "                              metrics.accuracy_score(validation_data.df['y_train'], validation_data.df['y_pred']), \n",
    "                              metrics.f1_score(validation_data.df['y_train'], validation_data.df['y_pred'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data.save('intermediate/2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras import backend as K\n",
    "from keras.callbacks import BaseLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', mode='max', min_delta=0, patience=10, verbose=0, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 200)               3200      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 201       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,401\n",
      "Trainable params: 3,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn = Sequential()\n",
    "nn.add(Dense(200, input_shape=[cf.feature_count()]))\n",
    "nn.add(Activation('sigmoid'))\n",
    "nn.add(Dense(1))\n",
    "nn.add(Activation('sigmoid'))\n",
    "nn.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f1])\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ScoreData.load('intermediate/2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = data.to_binary('y_pred')\n",
    "tmp = data_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.show_score(col=['x_train', 'y_train', 'y_pred', 'post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(data_pred)):\n",
    "    cnt = 0\n",
    "    highest = -1\n",
    "    lowest = 129\n",
    "    for j in range(0,128):\n",
    "        if data_pred[i][j] == 1:\n",
    "            highest = max(highest,j)\n",
    "            lowest = min(lowest,j)\n",
    "    for j in range(60,128):\n",
    "        if data_pred[i][j] ==1 and j < highest-12:\n",
    "            data_pred[i][j] = 0\n",
    "            data_pred[i][j+12] = 1\n",
    "    for j in reversed(range(0, 60)):\n",
    "        if data_pred[i][j] == 1 and j > lowest + 12:\n",
    "            data_pred[i][j] = 0\n",
    "            data_pred[i][j - 12] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import environment\n",
    "environment.set('musicxmlPath', '/usr/bin/musescore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.merge_binary(data_pred, name='post', skip_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
